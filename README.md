Базу тестовую поднимал в докере:

`docker-compose up -d postgres_db`

Для миграций я использовал `goose`.

`go install github.com/pressly/goose/v3/cmd/goose@latest`

Создать файл миграции:
`make create-migration-...`,

где ... - название миграции

Поднять миграции:
`make migration-up`

Откатить миграцию:
`make migration down`

Поднять проект:

1. `go install github.com/pressly/goose/v3/cmd/goose@latest`
2. optional `go install github.com/go-swagger/go-swagger/cmd/swagger@latest` или `brew install go-swagger` и в path нужно добавить `export PATH=$PATH:$HOME/go/bin`
3. установить докер
4. `docker-compose up -d postgres_db`
5. `make migrate-up`
6. `go run cmd/app/main.go`

проект запущен. Мог сделать в докер компоусе, но думаю и так ок. Докер файл я описал

Пересобрать доку - `make swag`

#

1. Что можно улучшить в схеме с БД?

В рамках авторизации я бы добавил рефрешы, чтобы каждые 24 часа не заставлять пользователя проходить авторизацию. Создать условную табличку с рефрешами и там хранить эти рефрешы, а потом фронт приходит, ловит token expired и импользуя рефреш создает новый акцес токен. Но мейби у сессии задачи немного больше, чем просто дать юзеру доступ к ресурсам.

Если нужно хранить ip, можно его фиксировать во время обмена рефреша на акцес токен, к примеру

2. Доработайте механизм авторизации таким образом, что бы в каждый момент времени у пользователя была активна только одна (последняя) сессия

Средал посредством удаления всех старых сессий перед созданием новой.

В идеале, делать софт делит, но я об этом выше рассуждал

Можно ещё не удалять их вообще никак, а просто создавать и потом при проверке токена мы сортируем по дате создания, от самого свежего к самому старому и проверяем его срок годности.

3. Ограничьте максимальное время пользовательской сессии до 24-х часов

Сделал. В `configs/main.yaml` можно это поменять.

4. Добавьте в БД данные об IP адресе авторизованного пользователя

Добавил. Чтобы обновить схему бд, нужно сделать `make migrate-up`

5. Реализуйте методы API для получения списка всех закаченных файлов

Сделал. Только я не совсем понимаю, что за assets будут хранится в бд. В ТЗ пишется, что нужно возвращать всё в json'e, но тут явно речь скорее всего про какой-то набор байт. Можно и в json'e вывести, можно и без. Я вывел данные в json'e, потому что существует ещё метод getAssets, который должен вывести все ассеты.

Но вообще, можно сделать чтобы этот метод выводил только мета информацию об ассетах, условное название, когда создано и чей этот ассет, а data не выводить, а уже если нужно получить этот ассет, то использовать ручку getAsset, и там уже вернётся чисто это что-то.

6. Реализуйте методы API для удаления файлов

Сделал через hard delete

7. Реализуйте работу сервера по протоколу HTTPS

Сделал, но с одним но. Я никогда не запускал веб сервер на гошке на https. Код в `internal/transport/rest/server.go` я написал, но я его не тестил, там нужен сертификат. В целом его не сложно выпустить, но не хочу)))))

Я всю жизнь настраивал ssl непосредственно на сервере. Накатывал бекенд (docker-compose, docker swarm, systemd unit), настраивал nginx на порт, который открыт для бекенда и настраивал через certbot. НЕ через certbot думаю не сильно сложнее будет.

Ну и плюс для сертификата вроде как домен нужен

#

**По поводу реализации сессий:**

Изначально хотел через jwt токены сделать, но там в тз описана модель сессий. Сделал через сессии в БД. Но я бы делал через jwt токены с рефрешами.

Так же думал как лучше сессии создавать. Продумал три варианта:
1. Проверить уже существующий токен. Если есть, вернуть его
2. Удалять все старые токены и создать новый токен
3. Создать новый токен и не удалять старые токены

Первый вариант минус. А вдруг старый токен существует, но он живёт 5 минут? По новой надо авторизовываться (или зарефрешить акцес токен, если сделать фичу с рефрешами)

Второй вариант нравится, в целом можно его использовать, но как удалять тоже вариант хороший. Можно просто стирать запить, а можно использовать soft delete и просто помечать запись как удалённую

Третий вариант, при поиске токена я буду сортировать по created_at DESC и брать только самый свежий токен искать и проверять.

А вообще авторизацию я бы сделал через jwt токены + рефрешы. Рефреши хранил бы в бд или лучше в редисе. Рефреш не сильно страшно потерять, зато при десятках миллионах записей поиск будет очень быстрый.

Но в рамках этой системы, лучше удалять неактуальные сессии. Поэтому при создании новой сессии я удаляю все старые сессии.

upd: после перечитки ТЗ, увидел, что там нужно добавить к сессии поле, хранящий ip адрес. При таких раскладах, лучше помечать запись удаленной, но не удалять физически из таблицы, либо использовать другой подход (где-то об этом я писал здесь)

А вообще, можно их удалять в кроне раз в условные сутки. Если сессия там 12 часов живёт, то раз в сутки запускать и удалять все сессии, котореы явно просрочены.

В рамказ тз я оставлю просто создание токенов без их чистки, но как это решить я написал

upd: сделал при создании новой сессии удаление всех (!) старых сессий. Сделал без транзакций, но вообще надо делать это в рамках транзакции.

Плюсом, после того, как я знал, что нужно ещё ip хранить в сессии, то лучше всего использовать soft delete для сессий. Условное поле deleted_at которое хранит дату. Если там null, то запить активна, если не null, то удалена и видно когда.

А потом в рамках задачи с логами можно будет выводить все сессии без учета deleted_at. А ну и при проверке токена так же нужно учитывать, чтобы deleted_at IS NULL.


**Удаление ассетов:**

По аналогу с сессиями. Можно сделать хард делит, можно софт делит. Я сделал хард делит, так быстрее.


**Прочие комментарии:**

Ручки несоответствую тому, что написано в ТЗ. То есть, конечные урлы у меня отличаются от тех, что в ТЗ:

POST ./api/v1/auth/login - авторизация

POST ./api/v1/asset/upload/:name - загрузить файл

GET ./api/v1/asset/:name - получить файл по названию

GET ./api/v1/asset/ - получить все файлы

DELETE ./api/v1/asset/:name - удалить файл по его названию

Когда включен дебаг - активен профайлер.

GET ./debug/pprof

Включил prometheus

GET ./metrics

Некоторые коды ответов не соответствуют тем, что в ТЗ. Я имею в виду именно код 403 Forbidden. В рамках этой схемы базы данных, в таблице assets primary key это name+uid. То есть имён может быть несколько, но обязательно, чтобы одно и то же имя не повторялось у одного и того же юзера. Поэтому и искать записи в БД следует используя name=? & uid=? и никак иначе. 

Поэтому, если я такой с asdasd_1, и кто-то ещё такой qweqwe_2, и я такой захочу получить файл с названием asdasd, я его получу (он мой), а вот на файл с названием qweqew я получу 404 not found, потому что он не мой.

Все остальные коды совпадают с тем, что они значат.

Так же написал доку на сваггере. До этого доку вёл в постмане, тут решил сваггер затестить. Не идеально, но прикольно получилось.